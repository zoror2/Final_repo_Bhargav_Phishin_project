{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8666106",
   "metadata": {},
   "source": [
    "# üöÄ Kaggle-Ready Phishing Detection LSTM Model\n",
    "\n",
    "This notebook preprocesses behavioral event data and builds an LSTM model for phishing URL detection.\n",
    "\n",
    "**‚ö° Optimized for Dual T4 GPU Training on Kaggle**\n",
    "\n",
    "**Dataset Structure:**\n",
    "- **Features**: 25 behavioral features including SSL validity, redirects, forms, scripts, page load times, etc.\n",
    "- **Target**: Binary classification (0 = legitimate, 1 = phishing)  \n",
    "- **Format**: Sequential behavioral events from URL visits\n",
    "- **Total samples**: 12,800+ URLs with comprehensive behavioral analysis\n",
    "- **Feature groups**: Basic behavioral features (13) + Count-based features (12)\n",
    "\n",
    "**Model Architecture:**\n",
    "- **Basic LSTM**: Simple architecture for baseline comparison with robust error handling\n",
    "- **Enhanced Bidirectional LSTM**: Advanced architecture with dual GPU support and comprehensive monitoring\n",
    "- **Full epoch training**: 150 epochs with no early stopping, best model auto-selected\n",
    "- **Deployment ready**: Complete prediction functions with 25-feature validation\n",
    "\n",
    "**Training Configuration:**\n",
    "- üî• **150 epochs** for improved model (no early stopping for optimal performance)\n",
    "- ‚ö° **Dual T4 GPU** support with MirroredStrategy on Kaggle\n",
    "- üéØ **Balanced training** with computed class weights  \n",
    "- üìä **Comprehensive monitoring** with memory tracking and detailed visualizations\n",
    "- üõ°Ô∏è **Robust error handling** throughout all training phases\n",
    "- üíæ **Memory management** with usage monitoring and optimization\n",
    "\n",
    "**Production Ready Features:**\n",
    "- ‚úÖ **Flexible data loading** with multiple path fallbacks for Kaggle/local environments\n",
    "- ‚úÖ **Enhanced validation** at every step with comprehensive error handling\n",
    "- ‚úÖ **Feature count verification** (exactly 25 features required for deployment)\n",
    "- ‚úÖ **Chrome extension integration** with detailed documentation and examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62314f25",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import all necessary libraries for data preprocessing, model building, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2877b4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import joblib\n",
    "from collections import defaultdict\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Deep learning libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Embedding, Bidirectional\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, CSVLogger, LearningRateScheduler\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Utilities\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Numpy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04a9451",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Dataset\n",
    "\n",
    "Load the preprocessed behavioral events dataset and explore its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68947f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset - optimized for Kaggle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load from Kaggle dataset path\n",
    "print(\"üìä Loading dataset...\")\n",
    "try:\n",
    "    df = pd.read_csv('/kaggle/input/phishing-dataset-full-lstm/events_dataset_full.csv')\n",
    "    print(f\"‚úÖ Dataset loaded successfully from Kaggle!\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading dataset: {e}\")\n",
    "    raise\n",
    "\n",
    "# Display basic info\n",
    "print(f\"\\nüìà Dataset Info:\")\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Total features: {df.shape[1] - 2}\")  # -2 for 'url' and 'label' columns\n",
    "print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
    "\n",
    "# Show class distribution\n",
    "print(f\"\\n‚öñÔ∏è Class Distribution:\")\n",
    "if 'label' in df.columns:\n",
    "    class_counts = df['label'].value_counts()\n",
    "    print(f\"Legitimate (0): {class_counts.get(0, 0)} ({class_counts.get(0, 0)/len(df)*100:.1f}%)\")\n",
    "    print(f\"Phishing (1): {class_counts.get(1, 0)} ({class_counts.get(1, 0)/len(df)*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"‚ùå 'label' column not found!\")\n",
    "\n",
    "# Display first few rows\n",
    "print(f\"\\nüìã Sample Data:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a72455",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Cleaning\n",
    "\n",
    "Clean and prepare the data for LSTM training. The dataset contains 25 behavioral features (excluding 'url' and 'label' columns) that characterize URL visiting behavior for phishing detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15144443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple data preprocessing for LSTM training\n",
    "print(\"üßπ Starting data preprocessing...\")\n",
    "\n",
    "# Make a copy for cleaning\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Remove URL column (not needed for training)\n",
    "if 'url' in df_clean.columns:\n",
    "    df_clean = df_clean.drop('url', axis=1)\n",
    "    print(\"üóëÔ∏è Removed 'url' column\")\n",
    "\n",
    "# Fill missing values with 0\n",
    "df_clean = df_clean.fillna(0)\n",
    "\n",
    "# Convert boolean success column to integer if it exists\n",
    "if 'success' in df_clean.columns:\n",
    "    df_clean['success'] = df_clean['success'].astype(int)\n",
    "\n",
    "# Remove duplicates\n",
    "print(f\"Removing duplicates: {len(df_clean)} ‚Üí \", end=\"\")\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "print(f\"{len(df_clean)}\")\n",
    "\n",
    "# Select feature columns (exclude target variable)\n",
    "feature_columns = [col for col in df_clean.columns if col != 'label']\n",
    "X = df_clean[feature_columns]\n",
    "y = df_clean['label']\n",
    "\n",
    "print(f\"\\n‚úÖ Data preprocessing completed:\")\n",
    "print(f\"   Features: {len(feature_columns)}\")\n",
    "print(f\"   Samples: {len(X)}\")\n",
    "print(f\"   Classes: {sorted(y.unique())}\")\n",
    "\n",
    "# Basic feature statistics\n",
    "print(f\"\\n\udcca Feature columns:\")\n",
    "for i, col in enumerate(feature_columns[:10]):  # Show first 10\n",
    "    print(f\"  {i+1}. {col}\")\n",
    "if len(feature_columns) > 10:\n",
    "    print(f\"  ... and {len(feature_columns)-10} more features\")\n",
    "\n",
    "# Check class balance\n",
    "class_counts = y.value_counts().sort_index()\n",
    "print(f\"\\n‚öñÔ∏è Class balance:\")\n",
    "for class_val, count in class_counts.items():\n",
    "    print(f\"   Class {class_val}: {count} samples ({count/len(y)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c74460",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering and Sequence Preparation\n",
    "\n",
    "Prepare features for LSTM input by creating sequences and normalizing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee52c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(f\"‚úÖ Features scaled. Shape: {X_scaled.shape}\")\n",
    "\n",
    "# For LSTM, we need to create sequences\n",
    "# Since each row represents behavioral features of a URL, we'll treat each sample as a sequence of length 1\n",
    "# Alternatively, we can create artificial sequences by grouping features\n",
    "\n",
    "# Method 1: Simple approach - reshape for LSTM (samples, timesteps=1, features)\n",
    "X_lstm = X_scaled.reshape(X_scaled.shape[0], 1, X_scaled.shape[1])\n",
    "\n",
    "print(f\"üìä LSTM input shape: {X_lstm.shape}\")\n",
    "print(f\"   - Samples: {X_lstm.shape[0]}\")\n",
    "print(f\"   - Time steps: {X_lstm.shape[1]}\")\n",
    "print(f\"   - Features: {X_lstm.shape[2]}\")\n",
    "\n",
    "# Alternative Method 2: Create multi-step sequences by grouping similar features\n",
    "# Group features by type for better sequence modeling\n",
    "feature_groups = {\n",
    "    'ssl_features': ['ssl_valid', 'ssl_invalid'],\n",
    "    'content_features': ['forms', 'password_fields', 'iframes', 'scripts', 'suspicious_keywords'],\n",
    "    'network_features': ['redirects', 'external_requests', 'page_load_time'],\n",
    "    'error_features': ['has_errors', 'success'],\n",
    "    'count_features': [col for col in feature_columns if col.startswith('count_')]\n",
    "}\n",
    "\n",
    "print(f\"\\nüéØ Feature groups:\")\n",
    "for group, features in feature_groups.items():\n",
    "    available_features = [f for f in features if f in feature_columns]\n",
    "    print(f\"   {group}: {len(available_features)} features\")\n",
    "\n",
    "# Create sequences using feature groups (optional alternative approach)\n",
    "def create_feature_sequences(X_data, feature_groups, feature_columns):\n",
    "    \"\"\"Create sequences by grouping related features\"\"\"\n",
    "    sequences = []\n",
    "    \n",
    "    for idx in range(len(X_data)):\n",
    "        sample = X_data[idx]\n",
    "        sequence = []\n",
    "        \n",
    "        # Create a sequence step for each feature group\n",
    "        for group_name, group_features in feature_groups.items():\n",
    "            available_features = [f for f in group_features if f in feature_columns]\n",
    "            if available_features:\n",
    "                # Get indices of these features\n",
    "                feature_indices = [feature_columns.index(f) for f in available_features]\n",
    "                # Extract values for this group\n",
    "                group_values = [sample[i] for i in feature_indices]\n",
    "                sequence.append(group_values)\n",
    "        \n",
    "        sequences.append(sequence)\n",
    "    \n",
    "    return sequences\n",
    "\n",
    "# Use simple approach for now (Method 1)\n",
    "print(f\"\\n‚úÖ Using simple LSTM sequence format\")\n",
    "print(f\"Final X shape for LSTM: {X_lstm.shape}\")\n",
    "print(f\"Final y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96678f30",
   "metadata": {},
   "source": [
    "## 5. Train-Test Split\n",
    "\n",
    "Split the data into training and testing sets for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132a465b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_lstm, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"üìä Data split completed:\")\n",
    "print(f\"   Training set: {X_train.shape} | {y_train.shape}\")\n",
    "print(f\"   Testing set: {X_test.shape} | {y_test.shape}\")\n",
    "\n",
    "print(f\"\\nüéØ Class distribution in training set:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"Training balance: {y_train.value_counts()[0] / y_train.value_counts()[1]:.2f}\")\n",
    "\n",
    "print(f\"\\nüéØ Class distribution in testing set:\")\n",
    "print(y_test.value_counts())\n",
    "print(f\"Testing balance: {y_test.value_counts()[0] / y_test.value_counts()[1]:.2f}\")\n",
    "\n",
    "# Convert to numpy arrays for TensorFlow\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(f\"\\n‚úÖ Data converted to numpy arrays\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89604f39",
   "metadata": {},
   "source": [
    "## 6. Build LSTM Model Architecture\n",
    "\n",
    "Define the LSTM model architecture for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a519b66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple LSTM Model Architecture\n",
    "def create_lstm_model(input_shape):\n",
    "    \"\"\"Create LSTM model for phishing detection\"\"\"\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "    \n",
    "    model = Sequential([\n",
    "        # LSTM layers\n",
    "        LSTM(128, return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        LSTM(64, return_sequences=False),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # Dense layers\n",
    "        Dense(50, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Dense(25, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # Output layer for binary classification\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])  # (timesteps, features)\n",
    "print(f\"üèóÔ∏è Creating LSTM model with input shape: {input_shape}\")\n",
    "\n",
    "model = create_lstm_model(input_shape)\n",
    "\n",
    "# Display model architecture\n",
    "print(\"üìä LSTM Model Architecture:\")\n",
    "model.summary()\n",
    "\n",
    "# Count parameters\n",
    "total_params = model.count_params()\n",
    "print(f\"\\nüìà Total parameters: {total_params:,}\")\n",
    "\n",
    "print(\"‚úÖ LSTM model created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4777fae",
   "metadata": {},
   "source": [
    "## 7. Compile and Train the Model\n",
    "\n",
    "Compile the model with appropriate optimizer and loss function, then train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61b6e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', 'precision', 'recall']\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Model compiled successfully!\")\n",
    "\n",
    "# Define callbacks (NO EARLY STOPPING - for comparison with improved model)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=5,\n",
    "    min_lr=0.0001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save best model without early stopping\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'basic_lstm_model_best.h5',\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1,\n",
    "    save_weights_only=False\n",
    ")\n",
    "\n",
    "callbacks = [reduce_lr, model_checkpoint]\n",
    "\n",
    "print(\"üìã Callbacks configured:\")\n",
    "print(\"   - Learning Rate Reduction (patience=5)\")\n",
    "print(\"   - ModelCheckpoint (saves best model)\")\n",
    "print(\"   - NO EARLY STOPPING - will train for full epochs\")\n",
    "\n",
    "# Train the model for full epochs\n",
    "print(\"\\nüöÄ Starting model training...\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=150,  # Full training epochs to match improved model\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Basic model training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a313147c",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation and Metrics\n",
    "\n",
    "Evaluate the trained model and visualize performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bde4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training and validation metrics\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Plot loss\n",
    "    axes[0, 0].plot(history.history['loss'], label='Training Loss')\n",
    "    axes[0, 0].plot(history.history['val_loss'], label='Validation Loss')\n",
    "    axes[0, 0].set_title('Model Loss')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # Plot accuracy\n",
    "    axes[0, 1].plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    axes[0, 1].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    axes[0, 1].set_title('Model Accuracy')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    # Plot precision\n",
    "    axes[1, 0].plot(history.history['precision'], label='Training Precision')\n",
    "    axes[1, 0].plot(history.history['val_precision'], label='Validation Precision')\n",
    "    axes[1, 0].set_title('Model Precision')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Precision')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True)\n",
    "    \n",
    "    # Plot recall\n",
    "    axes[1, 1].plot(history.history['recall'], label='Training Recall')\n",
    "    axes[1, 1].plot(history.history['val_recall'], label='Validation Recall')\n",
    "    axes[1, 1].set_title('Model Recall')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Recall')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot training history\n",
    "plot_training_history(history)\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"üéØ Evaluating model on test set...\")\n",
    "test_loss, test_accuracy, test_precision, test_recall = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(f\"\\nüìä Test Set Performance:\")\n",
    "print(f\"   Loss: {test_loss:.4f}\")\n",
    "print(f\"   Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"   Precision: {test_precision:.4f}\")\n",
    "print(f\"   Recall: {test_recall:.4f}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred_proba = model.predict(X_test)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
    "\n",
    "# Calculate additional metrics\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"   ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "print(f\"\\nüìã Detailed Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Legitimate', 'Phishing']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493665a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix and ROC curve\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Legitimate', 'Phishing'],\n",
    "            yticklabels=['Legitimate', 'Phishing'],\n",
    "            ax=axes[0])\n",
    "axes[0].set_title('Confusion Matrix')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "axes[1].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "axes[1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "axes[1].set_xlim([0.0, 1.0])\n",
    "axes[1].set_ylim([0.0, 1.05])\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_ylabel('True Positive Rate')\n",
    "axes[1].set_title('ROC Curve')\n",
    "axes[1].legend(loc=\"lower right\")\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature importance analysis (approximate)\n",
    "print(\"\\nüîç Analyzing feature importance...\")\n",
    "\n",
    "# Since LSTM doesn't provide direct feature importance, we'll use a simple approach\n",
    "# Calculate correlation between features and predictions\n",
    "feature_importance = []\n",
    "for i in range(X_test.shape[2]):  # For each feature\n",
    "    feature_values = X_test[:, 0, i]  # Extract feature values (timestep 0)\n",
    "    correlation = np.corrcoef(feature_values, y_pred_proba.flatten())[0, 1]\n",
    "    feature_importance.append(abs(correlation))\n",
    "\n",
    "# Sort features by importance\n",
    "feature_names = feature_columns[:len(feature_importance)]  # Match length\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Plot top 10 most important features\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_features = importance_df.head(10)\n",
    "plt.barh(range(len(top_features)), top_features['importance'])\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Absolute Correlation with Predictions')\n",
    "plt.title('Top 10 Most Important Features')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Top 10 most important features:\")\n",
    "print(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67ce34d",
   "metadata": {},
   "source": [
    "## 9. Save Model and Predictions\n",
    "\n",
    "Save the trained model and generate predictions for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a75a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save('phishing_lstm_model.h5')\n",
    "print(\"‚úÖ Model saved as 'phishing_lstm_model.h5'\")\n",
    "\n",
    "# Save the scaler for future use\n",
    "import joblib\n",
    "joblib.dump(scaler, 'feature_scaler.pkl')\n",
    "print(\"‚úÖ Feature scaler saved as 'feature_scaler.pkl'\")\n",
    "\n",
    "# Save model architecture as JSON\n",
    "model_json = model.to_json()\n",
    "with open('model_architecture.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "print(\"‚úÖ Model architecture saved as 'model_architecture.json'\")\n",
    "\n",
    "# Save training history\n",
    "import pickle\n",
    "with open('training_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "print(\"‚úÖ Training history saved as 'training_history.pkl'\")\n",
    "\n",
    "# Create a summary report\n",
    "report = {\n",
    "    'model_performance': {\n",
    "        'test_accuracy': float(test_accuracy),\n",
    "        'test_precision': float(test_precision),\n",
    "        'test_recall': float(test_recall),\n",
    "        'test_loss': float(test_loss),\n",
    "        'roc_auc': float(roc_auc)\n",
    "    },\n",
    "    'dataset_info': {\n",
    "        'total_samples': len(df_clean),\n",
    "        'training_samples': len(X_train),\n",
    "        'testing_samples': len(X_test),\n",
    "        'num_features': X_train.shape[2],\n",
    "        'class_balance': {\n",
    "            'legitimate': int(class_counts[0]),\n",
    "            'phishing': int(class_counts[1])\n",
    "        }\n",
    "    },\n",
    "    'model_info': {\n",
    "        'total_parameters': int(total_params),\n",
    "        'input_shape': list(input_shape),\n",
    "        'architecture': 'LSTM with Dense layers'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save report as JSON\n",
    "with open('model_report.json', 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "print(\"‚úÖ Model report saved as 'model_report.json'\")\n",
    "\n",
    "# Display final summary\n",
    "print(f\"\\nüéâ Training Complete! Final Results:\")\n",
    "print(f\"   üìä Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"   üéØ Test Precision: {test_precision:.4f}\")\n",
    "print(f\"   üîç Test Recall: {test_recall:.4f}\")\n",
    "print(f\"   üìà ROC AUC: {roc_auc:.4f}\")\n",
    "print(f\"\\nüìÅ Files saved:\")\n",
    "print(f\"   - phishing_lstm_model.h5 (trained model)\")\n",
    "print(f\"   - feature_scaler.pkl (preprocessing scaler)\")\n",
    "print(f\"   - model_architecture.json (model structure)\")\n",
    "print(f\"   - training_history.pkl (training metrics)\")\n",
    "print(f\"   - model_report.json (performance summary)\")\n",
    "\n",
    "# Example prediction function\n",
    "def predict_phishing(url_features, model, scaler):\n",
    "    \"\"\"\n",
    "    Predict if a URL is phishing based on behavioral features\n",
    "    \n",
    "    Args:\n",
    "        url_features: List or array of behavioral features\n",
    "        model: Trained LSTM model\n",
    "        scaler: Fitted StandardScaler\n",
    "    \n",
    "    Returns:\n",
    "        probability of being phishing (0-1)\n",
    "    \"\"\"\n",
    "    # Ensure features are in the right format\n",
    "    features = np.array(url_features).reshape(1, -1)\n",
    "    \n",
    "    # Scale features\n",
    "    features_scaled = scaler.transform(features)\n",
    "    \n",
    "    # Reshape for LSTM (samples, timesteps, features)\n",
    "    features_lstm = features_scaled.reshape(1, 1, -1)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(features_lstm, verbose=0)[0][0]\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "print(f\"\\nüöÄ Model ready for deployment!\")\n",
    "print(f\"Use the predict_phishing() function to make predictions on new URLs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fa53ce",
   "metadata": {},
   "source": [
    "## 10. Improved Model with Better Hyperparameters\n",
    "\n",
    "Let's create an improved version with better architecture and hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8a503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced GPU Configuration for Kaggle Dual T4 GPUs\n",
    "print(\"üîß Configuring GPU environment for optimal training...\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# Comprehensive GPU detection and configuration\n",
    "try:\n",
    "    # List all available devices\n",
    "    devices = tf.config.list_physical_devices()\n",
    "    print(f\"\\nüì± All available devices:\")\n",
    "    for device in devices:\n",
    "        print(f\"   {device}\")\n",
    "    \n",
    "    # Focus on GPUs\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    print(f\"\\nüéÆ GPU Detection Results:\")\n",
    "    print(f\"   Available GPUs: {len(gpus)}\")\n",
    "    \n",
    "    if gpus:\n",
    "        for i, gpu in enumerate(gpus):\n",
    "            print(f\"   GPU {i}: {gpu}\")\n",
    "            \n",
    "        # Configure GPU memory growth to prevent OOM errors\n",
    "        print(f\"\\n‚öôÔ∏è Configuring GPU memory management...\")\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(\"   ‚úÖ Memory growth enabled for all GPUs\")\n",
    "        except RuntimeError as e:\n",
    "            print(f\"   ‚ö†Ô∏è Memory growth configuration failed: {e}\")\n",
    "            print(\"   This may occur if virtual GPUs are already initialized\")\n",
    "        \n",
    "        # Set GPU memory limit if needed (useful for preventing OOM)\n",
    "        try:\n",
    "            for i, gpu in enumerate(gpus):\n",
    "                tf.config.experimental.set_virtual_device_configuration(\n",
    "                    gpu,\n",
    "                    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*14)]  # 14GB per GPU\n",
    "                )\n",
    "            print(\"   ‚úÖ GPU memory limits configured (14GB per GPU)\")\n",
    "        except RuntimeError as e:\n",
    "            print(f\"   ‚ö†Ô∏è Memory limit configuration skipped: {e}\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è No GPUs detected - will use CPU training\")\n",
    "        print(\"   This will be significantly slower for LSTM training\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå GPU detection failed: {str(e)}\")\n",
    "    gpus = []\n",
    "\n",
    "# Configure distributed training strategy\n",
    "print(f\"\\nüåê Configuring training strategy...\")\n",
    "try:\n",
    "    if len(gpus) > 1:\n",
    "        # Multi-GPU strategy for Kaggle dual T4 setup\n",
    "        strategy = tf.distribute.MirroredStrategy()\n",
    "        print(f\"   üöÄ MirroredStrategy initialized\")\n",
    "        print(f\"   üî• Training will use {strategy.num_replicas_in_sync} GPUs in parallel\")\n",
    "        print(f\"   ‚ö° Expected performance boost: ~{strategy.num_replicas_in_sync*0.8:.1f}x\")\n",
    "        \n",
    "        # Optimize for dual GPU setup\n",
    "        tf.config.optimizer.set_jit(True)  # Enable XLA compilation\n",
    "        print(f\"   ‚úÖ XLA optimization enabled\")\n",
    "        \n",
    "    elif len(gpus) == 1:\n",
    "        strategy = tf.distribute.get_strategy()\n",
    "        print(f\"   üîß Single GPU strategy selected\")\n",
    "        print(f\"   üìä Will use: {gpus[0]}\")\n",
    "        \n",
    "        # Single GPU optimizations\n",
    "        tf.config.optimizer.set_jit(True)\n",
    "        print(f\"   ‚úÖ XLA optimization enabled\")\n",
    "        \n",
    "    else:\n",
    "        strategy = tf.distribute.get_strategy()\n",
    "        print(f\"   üíª CPU-only strategy selected\")\n",
    "        print(f\"   ‚ö†Ô∏è Training will be significantly slower without GPU\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Strategy configuration failed: {str(e)}\")\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "    print(f\"   üîÑ Falling back to default strategy\")\n",
    "\n",
    "print(f\"\\nüìä Final configuration:\")\n",
    "print(f\"   Strategy: {type(strategy).__name__}\")\n",
    "print(f\"   Devices: {strategy.num_replicas_in_sync}\")\n",
    "print(f\"   GPU Memory: {'Managed' if gpus else 'N/A'}\")\n",
    "\n",
    "# Memory usage estimation\n",
    "if gpus:\n",
    "    print(f\"\\nüíæ Memory usage estimation:\")\n",
    "    print(f\"   Model parameters: ~{improved_total_params if 'improved_total_params' in globals() else 'TBD'}\")\n",
    "    print(f\"   Batch size: 16 per GPU = {16 * strategy.num_replicas_in_sync} total\")\n",
    "    print(f\"   Expected GPU memory usage: ~8-12GB per GPU\")\n",
    "    print(f\"   Kaggle T4 GPU memory: 16GB per GPU\")\n",
    "    print(f\"   ‚úÖ Memory requirements should be satisfied\")\n",
    "\n",
    "# Improved Model Architecture with Enhanced Error Handling\n",
    "def create_improved_lstm_model(input_shape):\n",
    "    \"\"\"\n",
    "    Create improved LSTM model with comprehensive validation\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Tuple of (timesteps, features)\n",
    "    \n",
    "    Returns:\n",
    "        Compiled Keras model\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate input shape\n",
    "        if len(input_shape) != 2:\n",
    "            raise ValueError(f\"Expected input_shape length 2, got {len(input_shape)}\")\n",
    "        \n",
    "        timesteps, features = input_shape\n",
    "        if features != 25:\n",
    "            print(f\"‚ö†Ô∏è Warning: Expected 25 features, got {features}\")\n",
    "        \n",
    "        print(f\"üèóÔ∏è Building model for input shape: {input_shape}\")\n",
    "        \n",
    "        model = Sequential([\n",
    "            # Bidirectional LSTM layers for better pattern recognition\n",
    "            Bidirectional(LSTM(64, return_sequences=True, recurrent_dropout=0.2), \n",
    "                         input_shape=input_shape, name='bidirectional_lstm_1'),\n",
    "            Dropout(0.3, name='dropout_1'),\n",
    "            \n",
    "            Bidirectional(LSTM(32, return_sequences=False, recurrent_dropout=0.2),\n",
    "                         name='bidirectional_lstm_2'),\n",
    "            Dropout(0.3, name='dropout_2'),\n",
    "            \n",
    "            # Dense layers with regularization\n",
    "            Dense(64, activation='relu', name='dense_1'),\n",
    "            Dropout(0.4, name='dropout_3'),\n",
    "            \n",
    "            Dense(32, activation='relu', name='dense_2'),\n",
    "            Dropout(0.3, name='dropout_4'),\n",
    "            \n",
    "            Dense(16, activation='relu', name='dense_3'),\n",
    "            Dropout(0.2, name='dropout_5'),\n",
    "            \n",
    "            # Output layer\n",
    "            Dense(1, activation='sigmoid', name='output')\n",
    "        ])\n",
    "        \n",
    "        print(f\"‚úÖ Model architecture created successfully\")\n",
    "        return model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Model creation failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Calculate class weights for balanced training with error handling\n",
    "try:\n",
    "    if 'y_train' in globals():\n",
    "        class_weights = compute_class_weight(\n",
    "            'balanced',\n",
    "            classes=np.unique(y_train),\n",
    "            y=y_train\n",
    "        )\n",
    "        class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "        print(f\"\\nüéØ Class weights calculated: {class_weight_dict}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è y_train not available yet - will calculate class weights later\")\n",
    "        class_weight_dict = None\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Class weight calculation failed: {str(e)}\")\n",
    "    class_weight_dict = None\n",
    "\n",
    "# Create and compile the improved model within strategy scope\n",
    "print(f\"\\nüî® Creating improved model within strategy scope...\")\n",
    "try:\n",
    "    with strategy.scope():\n",
    "        # Validate input shape availability\n",
    "        if 'input_shape' not in globals():\n",
    "            print(f\"‚ö†Ô∏è input_shape not defined - using default\")\n",
    "            input_shape = (1, 25)  # Default shape for LSTM\n",
    "            \n",
    "        # Create the improved model\n",
    "        improved_model = create_improved_lstm_model(input_shape)\n",
    "        \n",
    "        # Compile with strategy scope\n",
    "        improved_model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005, clipnorm=1.0),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy', 'precision', 'recall']\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Model compiled successfully within strategy scope\")\n",
    "\n",
    "    print(f\"\\nüìä Improved Model Architecture Summary:\")\n",
    "    improved_model.summary()\n",
    "\n",
    "    # Count parameters\n",
    "    improved_total_params = improved_model.count_params()\n",
    "    print(f\"\\n\udcc8 Model Statistics:\")\n",
    "    print(f\"   Total parameters: {improved_total_params:,}\")\n",
    "    print(f\"   Trainable parameters: {improved_model.count_params():,}\")\n",
    "    print(f\"   Model size estimate: ~{improved_total_params * 4 / (1024*1024):.1f} MB\")\n",
    "\n",
    "    print(f\"\\n‚úÖ Improved model ready for dual GPU training!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Model creation/compilation failed: {str(e)}\")\n",
    "    print(f\"üîÑ Will attempt to continue with basic error handling...\")\n",
    "    improved_model = None\n",
    "    improved_total_params = 0\n",
    "\n",
    "# Validation checkpoint\n",
    "print(f\"\\nüîç Pre-training validation:\")\n",
    "print(f\"   Strategy: {'‚úÖ' if strategy else '‚ùå'} {type(strategy).__name__}\")\n",
    "print(f\"   Model: {'‚úÖ' if 'improved_model' in locals() and improved_model else '‚ùå'}\")\n",
    "print(f\"   GPUs: {'‚úÖ' if gpus else '‚ö†Ô∏è'} ({len(gpus)} detected)\")\n",
    "print(f\"   Class weights: {'‚úÖ' if class_weight_dict else '‚ö†Ô∏è'}\")\n",
    "\n",
    "if not gpus:\n",
    "    print(f\"\\n‚ö†Ô∏è IMPORTANT: No GPUs detected!\")\n",
    "    print(f\"   Training will be much slower on CPU\")\n",
    "    print(f\"   Consider enabling GPU runtime in Kaggle settings\")\n",
    "\n",
    "print(f\"\\nüöÄ GPU configuration complete - ready for enhanced training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff65f4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Training Configuration with Comprehensive Monitoring and Validation\n",
    "import psutil\n",
    "import gc\n",
    "\n",
    "def get_memory_usage():\n",
    "    \"\"\"Get current memory usage statistics\"\"\"\n",
    "    process = psutil.Process()\n",
    "    memory_info = process.memory_info()\n",
    "    return {\n",
    "        'rss_mb': memory_info.rss / (1024 * 1024),\n",
    "        'vms_mb': memory_info.vms / (1024 * 1024),\n",
    "        'available_mb': psutil.virtual_memory().available / (1024 * 1024),\n",
    "        'percent_used': psutil.virtual_memory().percent\n",
    "    }\n",
    "\n",
    "def log_gpu_memory():\n",
    "    \"\"\"Log GPU memory usage if available\"\"\"\n",
    "    try:\n",
    "        gpus = tf.config.list_physical_devices('GPU')\n",
    "        if gpus:\n",
    "            # Get GPU memory info\n",
    "            gpu_details = tf.config.experimental.get_memory_info('GPU:0')\n",
    "            return {\n",
    "                'current_mb': gpu_details['current'] / (1024 * 1024),\n",
    "                'peak_mb': gpu_details['peak'] / (1024 * 1024)\n",
    "            }\n",
    "    except:\n",
    "        pass\n",
    "    return {'current_mb': 0, 'peak_mb': 0}\n",
    "\n",
    "# Pre-training validation and setup\n",
    "print(\"üîç Pre-training validation and setup...\")\n",
    "\n",
    "# Validate all required variables\n",
    "required_vars = ['X_train', 'X_test', 'y_train', 'y_test', 'improved_model', 'strategy']\n",
    "missing_vars = [var for var in required_vars if var not in globals()]\n",
    "\n",
    "if missing_vars:\n",
    "    print(f\"‚ùå Missing required variables: {missing_vars}\")\n",
    "    print(f\"   Cannot proceed with training!\")\n",
    "    print(f\"   Please run previous cells first.\")\n",
    "else:\n",
    "    print(f\"‚úÖ All required variables available\")\n",
    "\n",
    "# Memory monitoring\n",
    "initial_memory = get_memory_usage()\n",
    "gpu_memory = log_gpu_memory()\n",
    "\n",
    "print(f\"\\nüíæ Initial Memory Status:\")\n",
    "print(f\"   RAM Usage: {initial_memory['rss_mb']:.1f} MB ({initial_memory['percent_used']:.1f}%)\")\n",
    "print(f\"   Available RAM: {initial_memory['available_mb']:.1f} MB\")\n",
    "if gpu_memory['current_mb'] > 0:\n",
    "    print(f\"   GPU Memory: {gpu_memory['current_mb']:.1f} MB\")\n",
    "else:\n",
    "    print(f\"   GPU Memory: Not available or not accessible\")\n",
    "\n",
    "# Data validation\n",
    "print(f\"\\nüìä Training Data Validation:\")\n",
    "print(f\"   X_train shape: {X_train.shape if 'X_train' in globals() else 'Not available'}\")\n",
    "print(f\"   y_train shape: {y_train.shape if 'y_train' in globals() else 'Not available'}\")\n",
    "print(f\"   X_test shape: {X_test.shape if 'X_test' in globals() else 'Not available'}\")\n",
    "print(f\"   y_test shape: {y_test.shape if 'y_test' in globals() else 'Not available'}\")\n",
    "\n",
    "if 'X_train' in globals() and 'y_train' in globals():\n",
    "    # Check for data consistency\n",
    "    print(f\"   Sample consistency: {'‚úÖ' if len(X_train) == len(y_train) else '‚ùå'}\")\n",
    "    print(f\"   Data types: X_train={X_train.dtype}, y_train={y_train.dtype}\")\n",
    "    print(f\"   Value ranges: X_train=[{X_train.min():.3f}, {X_train.max():.3f}]\")\n",
    "    print(f\"   Target classes: {np.unique(y_train)}\")\n",
    "    \n",
    "    # Memory estimation\n",
    "    data_size_mb = (X_train.nbytes + y_train.nbytes + X_test.nbytes + y_test.nbytes) / (1024 * 1024)\n",
    "    print(f\"   Dataset size: {data_size_mb:.1f} MB\")\n",
    "\n",
    "# Calculate class weights with validation\n",
    "print(f\"\\n‚öñÔ∏è Class Weight Calculation:\")\n",
    "try:\n",
    "    if 'y_train' in globals():\n",
    "        unique_classes = np.unique(y_train)\n",
    "        print(f\"   Classes found: {unique_classes}\")\n",
    "        \n",
    "        if len(unique_classes) == 2:\n",
    "            class_weights = compute_class_weight(\n",
    "                'balanced',\n",
    "                classes=unique_classes,\n",
    "                y=y_train\n",
    "            )\n",
    "            class_weight_dict = {int(cls): weight for cls, weight in zip(unique_classes, class_weights)}\n",
    "            \n",
    "            print(f\"   ‚úÖ Class weights: {class_weight_dict}\")\n",
    "            print(f\"   Balance ratio: {class_weight_dict[0]/class_weight_dict[1]:.2f}\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå Expected 2 classes, found {len(unique_classes)}\")\n",
    "            class_weight_dict = None\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è y_train not available\")\n",
    "        class_weight_dict = None\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Class weight calculation failed: {str(e)}\")\n",
    "    class_weight_dict = None\n",
    "\n",
    "# Enhanced callbacks for comprehensive monitoring\n",
    "print(f\"\\nüìã Configuring enhanced callbacks...\")\n",
    "\n",
    "callbacks_list = []\n",
    "\n",
    "# 1. Model checkpoint (save best model)\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    'best_improved_model.h5',\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1,\n",
    "    save_weights_only=False\n",
    ")\n",
    "callbacks_list.append(model_checkpoint)\n",
    "print(f\"   ‚úÖ ModelCheckpoint: Save best model based on val_accuracy\")\n",
    "\n",
    "# 2. Learning rate reduction\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=15,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1,\n",
    "    cooldown=5\n",
    ")\n",
    "callbacks_list.append(reduce_lr)\n",
    "print(f\"   ‚úÖ ReduceLROnPlateau: Reduce LR when val_loss plateaus\")\n",
    "\n",
    "# 3. CSV Logger for detailed training logs\n",
    "csv_logger = tf.keras.callbacks.CSVLogger('improved_training_log.csv', append=False)\n",
    "callbacks_list.append(csv_logger)\n",
    "print(f\"   ‚úÖ CSVLogger: Log training metrics to file\")\n",
    "\n",
    "# 4. Learning rate scheduler\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Custom learning rate schedule\"\"\"\n",
    "    initial_lr = 0.0005\n",
    "    if epoch < 30:\n",
    "        return initial_lr\n",
    "    elif epoch < 60:\n",
    "        return initial_lr * 0.5\n",
    "    elif epoch < 100:\n",
    "        return initial_lr * 0.25\n",
    "    else:\n",
    "        return initial_lr * 0.1\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule, verbose=0)\n",
    "callbacks_list.append(lr_scheduler)\n",
    "print(f\"   ‚úÖ LearningRateScheduler: Custom LR schedule over 150 epochs\")\n",
    "\n",
    "# 5. Custom callback for memory monitoring\n",
    "class MemoryMonitorCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.epoch_memory = []\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 10 == 0:  # Log every 10 epochs\n",
    "            memory = get_memory_usage()\n",
    "            gpu_mem = log_gpu_memory()\n",
    "            self.epoch_memory.append({\n",
    "                'epoch': epoch,\n",
    "                'memory_mb': memory['rss_mb'],\n",
    "                'gpu_memory_mb': gpu_mem['current_mb']\n",
    "            })\n",
    "            \n",
    "            if epoch % 25 == 0:  # Print every 25 epochs\n",
    "                print(f\"   \udcca Epoch {epoch}: RAM {memory['rss_mb']:.1f}MB, GPU {gpu_mem['current_mb']:.1f}MB\")\n",
    "\n",
    "memory_monitor = MemoryMonitorCallback()\n",
    "callbacks_list.append(memory_monitor)\n",
    "print(f\"   ‚úÖ MemoryMonitor: Track memory usage during training\")\n",
    "\n",
    "# Training configuration validation\n",
    "batch_size = 16\n",
    "epochs = 150\n",
    "validation_split = 0.25\n",
    "\n",
    "print(f\"\\n\ude80 Final Training Configuration:\")\n",
    "print(f\"   Model: {'‚úÖ Ready' if 'improved_model' in globals() else '‚ùå Not ready'}\")\n",
    "print(f\"   Strategy: {'‚úÖ' if 'strategy' in globals() else '‚ùå'} {type(strategy).__name__ if 'strategy' in globals() else 'Unknown'}\")\n",
    "print(f\"   GPUs: {strategy.num_replicas_in_sync if 'strategy' in globals() else 'Unknown'}\")\n",
    "print(f\"   Batch size: {batch_size} per replica = {batch_size * (strategy.num_replicas_in_sync if 'strategy' in globals() else 1)} total\")\n",
    "print(f\"   Epochs: {epochs} (FULL TRAINING - NO EARLY STOPPING)\")\n",
    "print(f\"   Validation split: {validation_split}\")\n",
    "print(f\"   Class weights: {'‚úÖ Applied' if class_weight_dict else '‚ùå Not applied'}\")\n",
    "print(f\"   Callbacks: {len(callbacks_list)} configured\")\n",
    "\n",
    "# Memory requirement estimation\n",
    "if 'improved_model' in globals():\n",
    "    model_params = improved_model.count_params()\n",
    "    estimated_memory_mb = (model_params * 4 * 3) / (1024 * 1024)  # Parameters * 4 bytes * 3 (weights, gradients, optimizer)\n",
    "    print(f\"   Estimated training memory: {estimated_memory_mb:.1f} MB\")\n",
    "    \n",
    "    if initial_memory['available_mb'] < estimated_memory_mb * 1.5:\n",
    "        print(f\"   ‚ö†Ô∏è WARNING: May run out of memory during training!\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ Sufficient memory available\")\n",
    "\n",
    "# Force garbage collection\n",
    "gc.collect()\n",
    "\n",
    "# Start training with comprehensive monitoring\n",
    "if missing_vars:\n",
    "    print(f\"\\n‚ùå Cannot start training due to missing variables: {missing_vars}\")\n",
    "else:\n",
    "    print(f\"\\nüöÄ Starting enhanced training with full monitoring...\")\n",
    "    print(f\"üìù Training will run for ALL {epochs} epochs (no early stopping)\")\n",
    "    print(f\"‚ö° Using {strategy.num_replicas_in_sync} GPU(s) with MirroredStrategy\")\n",
    "    print(f\"üíæ Memory usage will be monitored every 10 epochs\")\n",
    "    print(f\"üìä Best model will be saved automatically\")\n",
    "    print(f\"üìà Training progress logged to 'improved_training_log.csv'\")\n",
    "    \n",
    "    # Record training start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Start training with all enhancements\n",
    "        improved_history = improved_model.fit(\n",
    "            X_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_split=validation_split,\n",
    "            callbacks=callbacks_list,\n",
    "            class_weight=class_weight_dict if class_weight_dict else None,\n",
    "            verbose=1,\n",
    "            shuffle=True,\n",
    "            workers=4,  # Use multiple workers for data loading\n",
    "            use_multiprocessing=True\n",
    "        )\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"\\nüéâ TRAINING COMPLETED SUCCESSFULLY!\")\n",
    "        print(f\"‚è±Ô∏è  Total training time: {training_time/3600:.2f} hours ({training_time/60:.1f} minutes)\")\n",
    "        print(f\"‚ö° Average time per epoch: {training_time/epochs:.1f} seconds\")\n",
    "        print(f\"‚úÖ All {epochs} epochs completed without early stopping\")\n",
    "        print(f\"üíæ Best model automatically saved to 'best_improved_model.h5'\")\n",
    "        \n",
    "        # Final memory check\n",
    "        final_memory = get_memory_usage()\n",
    "        final_gpu_memory = log_gpu_memory()\n",
    "        \n",
    "        print(f\"\\nüìä Final Memory Status:\")\n",
    "        print(f\"   RAM: {final_memory['rss_mb']:.1f} MB (change: {final_memory['rss_mb'] - initial_memory['rss_mb']:+.1f} MB)\")\n",
    "        if final_gpu_memory['current_mb'] > 0:\n",
    "            print(f\"   GPU: {final_gpu_memory['current_mb']:.1f} MB (peak: {final_gpu_memory['peak_mb']:.1f} MB)\")\n",
    "        \n",
    "        # Save memory monitoring data\n",
    "        if hasattr(memory_monitor, 'epoch_memory') and memory_monitor.epoch_memory:\n",
    "            memory_df = pd.DataFrame(memory_monitor.epoch_memory)\n",
    "            memory_df.to_csv('training_memory_log.csv', index=False)\n",
    "            print(f\"   üíæ Memory usage log saved to 'training_memory_log.csv'\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        training_time = time.time() - start_time\n",
    "        print(f\"\\n‚ùå TRAINING FAILED!\")\n",
    "        print(f\"   Error: {str(e)}\")\n",
    "        print(f\"   Time before failure: {training_time/60:.1f} minutes\")\n",
    "        print(f\"   Check logs and memory usage\")\n",
    "        \n",
    "        # Save partial results if available\n",
    "        try:\n",
    "            if 'improved_history' in locals():\n",
    "                with open('partial_training_history.pkl', 'wb') as f:\n",
    "                    pickle.dump(improved_history.history, f)\n",
    "                print(f\"   üíæ Partial training history saved\")\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        raise  # Re-raise the exception for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d873bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model (automatically saved during 150 epochs training)\n",
    "print(\"üì¶ Loading best improved model from 150 epochs...\")\n",
    "best_improved_model = tf.keras.models.load_model('best_improved_model.h5')\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"üß™ Evaluating best improved model on test set...\")\n",
    "improved_test_loss, improved_test_accuracy, improved_test_precision, improved_test_recall = best_improved_model.evaluate(\n",
    "    X_test, y_test, verbose=0\n",
    ")\n",
    "\n",
    "# Calculate F1-score and other metrics\n",
    "y_pred_improved = (best_improved_model.predict(X_test) > 0.5).astype(int)\n",
    "y_pred_improved_proba = best_improved_model.predict(X_test)\n",
    "\n",
    "improved_test_f1 = f1_score(y_test, y_pred_improved)\n",
    "improved_roc_auc = roc_auc_score(y_test, y_pred_improved_proba)\n",
    "\n",
    "print(f\"\\nüéØ FINAL IMPROVED MODEL RESULTS (Best from 150 epochs):\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Test Accuracy:  {improved_test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {improved_test_precision:.4f}\")\n",
    "print(f\"Test Recall:    {improved_test_recall:.4f}\")\n",
    "print(f\"Test F1-Score:  {improved_test_f1:.4f}\")\n",
    "print(f\"ROC AUC:        {improved_roc_auc:.4f}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Get model parameters\n",
    "improved_total_params = best_improved_model.count_params()\n",
    "print(f\"üìä Model Parameters: {improved_total_params:,}\")\n",
    "\n",
    "# Find the best epoch from training history\n",
    "best_epoch = np.argmax(improved_history.history['val_accuracy']) + 1\n",
    "best_val_accuracy = max(improved_history.history['val_accuracy'])\n",
    "print(f\"üèÜ Best epoch: {best_epoch}/150 (Validation Accuracy: {best_val_accuracy:.4f})\")\n",
    "\n",
    "# Plot comprehensive training history for all 150 epochs\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# Training & Validation Loss\n",
    "axes[0, 0].plot(improved_history.history['loss'], label='Training Loss', color='blue')\n",
    "axes[0, 0].plot(improved_history.history['val_loss'], label='Validation Loss', color='red')\n",
    "axes[0, 0].axvline(x=best_epoch-1, color='green', linestyle='--', alpha=0.7, label=f'Best Epoch ({best_epoch})')\n",
    "axes[0, 0].set_title('Model Loss Over 150 Epochs')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Training & Validation Accuracy\n",
    "axes[0, 1].plot(improved_history.history['accuracy'], label='Training Accuracy', color='blue')\n",
    "axes[0, 1].plot(improved_history.history['val_accuracy'], label='Validation Accuracy', color='red')\n",
    "axes[0, 1].axvline(x=best_epoch-1, color='green', linestyle='--', alpha=0.7, label=f'Best Epoch ({best_epoch})')\n",
    "axes[0, 1].set_title('Model Accuracy Over 150 Epochs')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning Rate Schedule (check if exists in history)\n",
    "if 'lr' in improved_history.history:\n",
    "    axes[0, 2].plot(improved_history.history['lr'], label='Learning Rate', color='green')\n",
    "    axes[0, 2].set_title('Learning Rate Schedule')\n",
    "    axes[0, 2].set_xlabel('Epoch')\n",
    "    axes[0, 2].set_ylabel('Learning Rate')\n",
    "    axes[0, 2].set_yscale('log')\n",
    "    axes[0, 2].legend()\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "else:\n",
    "    # If no learning rate history, plot validation F1 approximation\n",
    "    val_f1_approx = []\n",
    "    for i in range(len(improved_history.history['val_precision'])):\n",
    "        p = improved_history.history['val_precision'][i]\n",
    "        r = improved_history.history['val_recall'][i]\n",
    "        f1 = 2 * (p * r) / (p + r) if (p + r) > 0 else 0\n",
    "        val_f1_approx.append(f1)\n",
    "    \n",
    "    axes[0, 2].plot(val_f1_approx, label='Validation F1-Score', color='purple')\n",
    "    axes[0, 2].set_title('Validation F1-Score Over Time')\n",
    "    axes[0, 2].set_xlabel('Epoch')\n",
    "    axes[0, 2].set_ylabel('F1-Score')\n",
    "    axes[0, 2].legend()\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# Precision & Recall\n",
    "axes[1, 0].plot(improved_history.history['precision'], label='Training Precision', color='blue')\n",
    "axes[1, 0].plot(improved_history.history['val_precision'], label='Validation Precision', color='red')\n",
    "axes[1, 0].plot(improved_history.history['recall'], label='Training Recall', color='blue', linestyle='--')\n",
    "axes[1, 0].plot(improved_history.history['val_recall'], label='Validation Recall', color='red', linestyle='--')\n",
    "axes[1, 0].axvline(x=best_epoch-1, color='green', linestyle='--', alpha=0.7, label=f'Best Epoch ({best_epoch})')\n",
    "axes[1, 0].set_title('Precision & Recall Over 150 Epochs')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Score')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_improved = confusion_matrix(y_test, y_pred_improved)\n",
    "sns.heatmap(cm_improved, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Legitimate', 'Phishing'],\n",
    "            yticklabels=['Legitimate', 'Phishing'],\n",
    "            ax=axes[1, 1])\n",
    "axes[1, 1].set_title(f'Best Model Confusion Matrix\\n(Epoch {best_epoch})')\n",
    "\n",
    "# ROC Curve\n",
    "fpr_improved, tpr_improved, _ = roc_curve(y_test, y_pred_improved_proba)\n",
    "axes[1, 2].plot(fpr_improved, tpr_improved, color='blue', lw=2, \n",
    "                label=f'Best Model (AUC = {improved_roc_auc:.4f})')\n",
    "axes[1, 2].plot([0, 1], [0, 1], color='red', lw=1, linestyle='--', alpha=0.5)\n",
    "axes[1, 2].set_xlim([0.0, 1.0])\n",
    "axes[1, 2].set_ylim([0.0, 1.05])\n",
    "axes[1, 2].set_xlabel('False Positive Rate')\n",
    "axes[1, 2].set_ylabel('True Positive Rate')\n",
    "axes[1, 2].set_title(f'ROC Curve - Best Model\\n(Epoch {best_epoch})')\n",
    "axes[1, 2].legend(loc=\"lower right\")\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the final best model for deployment\n",
    "best_improved_model.save('phishing_lstm_model_final.h5')\n",
    "print(\"‚úÖ Final optimized model saved as 'phishing_lstm_model_final.h5'\")\n",
    "\n",
    "# Also save the scaler for deployment\n",
    "joblib.dump(scaler, 'feature_scaler_final.pkl')\n",
    "print(\"‚úÖ Feature scaler saved as 'feature_scaler_final.pkl'\")\n",
    "\n",
    "# Create comprehensive final report\n",
    "final_report = {\n",
    "    'training_info': {\n",
    "        'total_epochs_completed': 150,\n",
    "        'best_epoch': int(best_epoch),\n",
    "        'best_validation_accuracy': float(best_val_accuracy),\n",
    "        'early_stopping_used': False,\n",
    "        'training_time_minutes': float(training_time/60)\n",
    "    },\n",
    "    'model_info': {\n",
    "        'architecture': 'Bidirectional LSTM',\n",
    "        'parameters': int(improved_total_params),\n",
    "        'gpus_used': strategy.num_replicas_in_sync,\n",
    "        'input_shape': list(input_shape)\n",
    "    },\n",
    "    'performance_metrics': {\n",
    "        'test_accuracy': float(improved_test_accuracy),\n",
    "        'test_precision': float(improved_test_precision),\n",
    "        'test_recall': float(improved_test_recall),\n",
    "        'test_f1_score': float(improved_test_f1),\n",
    "        'roc_auc': float(improved_roc_auc)\n",
    "    },\n",
    "    'training_config': {\n",
    "        'learning_rate_initial': 0.0005,\n",
    "        'batch_size': 16,\n",
    "        'validation_split': 0.25,\n",
    "        'class_weights': class_weight_dict\n",
    "    },\n",
    "    'dataset_info': {\n",
    "        'total_samples': len(df_clean),\n",
    "        'training_samples': len(X_train),\n",
    "        'testing_samples': len(X_test),\n",
    "        'num_features': X_train.shape[2]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save final report\n",
    "with open('final_model_report.json', 'w') as f:\n",
    "    json.dump(final_report, f, indent=2)\n",
    "print(\"‚úÖ Final model report saved\")\n",
    "\n",
    "# Save feature column names for deployment reference\n",
    "feature_info = {\n",
    "    'feature_columns': feature_columns,\n",
    "    'total_features': len(feature_columns),\n",
    "    'feature_groups': {\n",
    "        'ssl_features': ['ssl_valid', 'ssl_invalid'],\n",
    "        'content_features': ['forms', 'password_fields', 'iframes', 'scripts', 'suspicious_keywords'],\n",
    "        'network_features': ['redirects', 'external_requests', 'page_load_time'],\n",
    "        'error_features': ['has_errors', 'success'],\n",
    "        'count_features': [col for col in feature_columns if col.startswith('count_')]\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('feature_info.json', 'w') as f:\n",
    "    json.dump(feature_info, f, indent=2)\n",
    "print(\"‚úÖ Feature information saved\")\n",
    "\n",
    "print(f\"\\nüéâ DUAL GPU TRAINING COMPLETE - ALL 150 EPOCHS!\")\n",
    "print(f\"üèÜ Best model selected from epoch {best_epoch} out of 150\")\n",
    "print(f\"üöÄ Model ready for Chrome extension deployment!\")\n",
    "print(f\"‚ö° Trained on {strategy.num_replicas_in_sync} GPU(s) for maximum performance!\")\n",
    "print(f\"üìà Training improvement: Model trained for full 150 epochs, best automatically selected\")\n",
    "\n",
    "print(f\"\\nüìÅ Files ready for download:\")\n",
    "print(f\"   - phishing_lstm_model_final.h5 (optimized model)\")\n",
    "print(f\"   - feature_scaler_final.pkl (feature scaler)\")\n",
    "print(f\"   - final_model_report.json (performance metrics)\")\n",
    "print(f\"   - feature_info.json (feature configuration)\")\n",
    "print(f\"   - improved_training_log.csv (training logs)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d4866c",
   "metadata": {},
   "source": [
    "## 11. Deployment-Ready Prediction Function\n",
    "\n",
    "Create a complete prediction function for Chrome extension integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c08b281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create deployment-ready prediction function with robust error handling\n",
    "def predict_phishing_deployment(url_features, model_path='phishing_lstm_model_final.h5', scaler_path='feature_scaler_final.pkl'):\n",
    "    \"\"\"\n",
    "    Complete deployment-ready function for phishing prediction\n",
    "    \n",
    "    Args:\n",
    "        url_features: List or array of 25 behavioral features (excluding 'url' and 'label' columns)\n",
    "        model_path: Path to the trained model\n",
    "        scaler_path: Path to the fitted scaler\n",
    "    \n",
    "    Returns:\n",
    "        dict: {\n",
    "            'probability': float (0-1),\n",
    "            'prediction': str ('legitimate' or 'phishing'),\n",
    "            'confidence': str ('low', 'medium', 'high'),\n",
    "            'model_version': str,\n",
    "            'feature_count': int\n",
    "        }\n",
    "    \"\"\"\n",
    "    import tensorflow as tf\n",
    "    import joblib\n",
    "    import numpy as np\n",
    "    import os\n",
    "    \n",
    "    try:\n",
    "        # Validate file existence\n",
    "        if not os.path.exists(model_path):\n",
    "            return {\n",
    "                'error': f'Model file not found: {model_path}',\n",
    "                'probability': 0.5,\n",
    "                'prediction': 'unknown',\n",
    "                'confidence': 'low'\n",
    "            }\n",
    "            \n",
    "        if not os.path.exists(scaler_path):\n",
    "            return {\n",
    "                'error': f'Scaler file not found: {scaler_path}',\n",
    "                'probability': 0.5,\n",
    "                'prediction': 'unknown',\n",
    "                'confidence': 'low'\n",
    "            }\n",
    "        \n",
    "        # Load model and scaler with error handling\n",
    "        try:\n",
    "            model = tf.keras.models.load_model(model_path)\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'error': f'Failed to load model: {str(e)}',\n",
    "                'probability': 0.5,\n",
    "                'prediction': 'unknown',\n",
    "                'confidence': 'low'\n",
    "            }\n",
    "            \n",
    "        try:\n",
    "            scaler = joblib.load(scaler_path)\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'error': f'Failed to load scaler: {str(e)}',\n",
    "                'probability': 0.5,\n",
    "                'prediction': 'unknown',\n",
    "                'confidence': 'low'\n",
    "            }\n",
    "        \n",
    "        # Validate input features - expecting 25 features\n",
    "        expected_features = 25  # Based on dataset: 26 total columns - 'url' - 'label' = 24 features\n",
    "        if not isinstance(url_features, (list, np.ndarray)):\n",
    "            return {\n",
    "                'error': f'url_features must be list or numpy array, got {type(url_features)}',\n",
    "                'probability': 0.5,\n",
    "                'prediction': 'unknown',\n",
    "                'confidence': 'low'\n",
    "            }\n",
    "            \n",
    "        if len(url_features) != expected_features:\n",
    "            return {\n",
    "                'error': f'Expected {expected_features} features, got {len(url_features)}',\n",
    "                'probability': 0.5,\n",
    "                'prediction': 'unknown',\n",
    "                'confidence': 'low',\n",
    "                'expected_features': expected_features,\n",
    "                'received_features': len(url_features)\n",
    "            }\n",
    "        \n",
    "        # Validate feature values\n",
    "        features_array = np.array(url_features, dtype=np.float32)\n",
    "        if np.any(np.isnan(features_array)):\n",
    "            return {\n",
    "                'error': 'Input features contain NaN values',\n",
    "                'probability': 0.5,\n",
    "                'prediction': 'unknown',\n",
    "                'confidence': 'low'\n",
    "            }\n",
    "            \n",
    "        if np.any(np.isinf(features_array)):\n",
    "            return {\n",
    "                'error': 'Input features contain infinite values',\n",
    "                'probability': 0.5,\n",
    "                'prediction': 'unknown',\n",
    "                'confidence': 'low'\n",
    "            }\n",
    "        \n",
    "        # Prepare features\n",
    "        features = features_array.reshape(1, -1)\n",
    "        \n",
    "        # Scale features\n",
    "        try:\n",
    "            features_scaled = scaler.transform(features)\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'error': f'Feature scaling failed: {str(e)}',\n",
    "                'probability': 0.5,\n",
    "                'prediction': 'unknown',\n",
    "                'confidence': 'low'\n",
    "            }\n",
    "        \n",
    "        # Reshape for LSTM (samples, timesteps, features)\n",
    "        features_lstm = features_scaled.reshape(1, 1, -1)\n",
    "        \n",
    "        # Validate LSTM input shape\n",
    "        expected_input_shape = model.input_shape\n",
    "        actual_input_shape = features_lstm.shape\n",
    "        \n",
    "        if expected_input_shape[1:] != actual_input_shape[1:]:\n",
    "            return {\n",
    "                'error': f'Input shape mismatch. Expected: {expected_input_shape}, Got: {actual_input_shape}',\n",
    "                'probability': 0.5,\n",
    "                'prediction': 'unknown',\n",
    "                'confidence': 'low'\n",
    "            }\n",
    "        \n",
    "        # Make prediction\n",
    "        try:\n",
    "            prediction_raw = model.predict(features_lstm, verbose=0)\n",
    "            probability = float(prediction_raw[0][0])\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'error': f'Model prediction failed: {str(e)}',\n",
    "                'probability': 0.5,\n",
    "                'prediction': 'unknown',\n",
    "                'confidence': 'low'\n",
    "            }\n",
    "        \n",
    "        # Validate probability\n",
    "        if not (0 <= probability <= 1):\n",
    "            probability = max(0, min(1, probability))  # Clamp to [0,1]\n",
    "        \n",
    "        # Determine prediction and confidence\n",
    "        if probability > 0.5:\n",
    "            prediction = 'phishing'\n",
    "            confidence_score = probability\n",
    "        else:\n",
    "            prediction = 'legitimate'\n",
    "            confidence_score = 1 - probability\n",
    "            \n",
    "        # Enhanced confidence levels\n",
    "        if confidence_score < 0.6:  # 0.5-0.6 range\n",
    "            confidence = 'low'\n",
    "        elif confidence_score < 0.8:  # 0.6-0.8 range\n",
    "            confidence = 'medium'\n",
    "        else:  # 0.8-1.0 range\n",
    "            confidence = 'high'\n",
    "        \n",
    "        return {\n",
    "            'probability': probability,\n",
    "            'prediction': prediction,\n",
    "            'confidence': confidence,\n",
    "            'model_version': 'LSTM_v2.0',\n",
    "            'feature_count': len(url_features),\n",
    "            'confidence_score': confidence_score\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'error': f'Unexpected error in prediction: {str(e)}',\n",
    "            'probability': 0.5,\n",
    "            'prediction': 'unknown',\n",
    "            'confidence': 'low'\n",
    "        }\n",
    "\n",
    "# Test the deployment function with comprehensive validation\n",
    "print(\"üß™ Testing deployment function with comprehensive validation...\")\n",
    "\n",
    "# Test with correct number of features (25)\n",
    "sample_features_25 = [\n",
    "    1, 5, 1, 0, 2, 1, 0, 3, 8, 1, 5, 2500, 0,  # Basic behavioral features (13)\n",
    "    0.0, 0.0, 1.0, 2.0, 5.0, 1.0, 0.0, 3.0, 8.0, 1.0, 5.0, 2500.0  # Count features (12)\n",
    "]  # Total: 25 features\n",
    "\n",
    "print(f\"‚úÖ Testing with {len(sample_features_25)} features (expected: 25)\")\n",
    "result = predict_phishing_deployment(sample_features_25)\n",
    "print(f\"Sample prediction result: {result}\")\n",
    "\n",
    "# Test with incorrect number of features\n",
    "print(f\"\\nüß™ Testing error handling with wrong feature count...\")\n",
    "sample_features_wrong = [1, 2, 3, 4, 5]  # Only 5 features\n",
    "result_error = predict_phishing_deployment(sample_features_wrong)\n",
    "print(f\"Error handling result: {result_error}\")\n",
    "\n",
    "# Feature mapping documentation\n",
    "feature_mapping = {\n",
    "    'basic_features': [\n",
    "        'success', 'num_events', 'ssl_valid', 'ssl_invalid', 'redirects', \n",
    "        'forms', 'password_fields', 'iframes', 'scripts', 'suspicious_keywords',\n",
    "        'external_requests', 'page_load_time', 'has_errors'\n",
    "    ],\n",
    "    'count_features': [\n",
    "        'count_ssl_invalid', 'count_webdriver_error', 'count_ssl_valid',\n",
    "        'count_redirects', 'count_external_requests', 'count_forms_detected',\n",
    "        'count_password_fields', 'count_iframes_detected', 'count_scripts_detected',\n",
    "        'count_suspicious_keywords', 'count_page_load_time'\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(f\"\\nüìã Feature Mapping for Deployment (25 features total):\")\n",
    "print(f\"Basic features (13): {feature_mapping['basic_features']}\")\n",
    "print(f\"Count features (12): {feature_mapping['count_features']}\")\n",
    "\n",
    "# Save the enhanced deployment function\n",
    "deployment_code = f'''\"\"\"\n",
    "Phishing Detection Model - Enhanced Deployment Function\n",
    "Chrome Extension Integration Ready - Version 2.0\n",
    "Features: 25 behavioral features (excluding 'url' and 'label')\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def predict_phishing(url_features, model_path='phishing_lstm_model_final.h5', scaler_path='feature_scaler_final.pkl'):\n",
    "    \"\"\"\n",
    "    Enhanced phishing prediction with comprehensive error handling\n",
    "    \n",
    "    Args:\n",
    "        url_features: List of exactly 25 behavioral features in this order:\n",
    "                     {feature_mapping['basic_features'] + feature_mapping['count_features']}\n",
    "        model_path: Path to trained LSTM model (.h5 file)\n",
    "        scaler_path: Path to feature scaler (.pkl file)\n",
    "    \n",
    "    Returns:\n",
    "        dict: {{\n",
    "            'probability': float (0-1, phishing probability),\n",
    "            'prediction': str ('legitimate' or 'phishing'),\n",
    "            'confidence': str ('low', 'medium', 'high'),\n",
    "            'model_version': str,\n",
    "            'error': str (if any error occurred)\n",
    "        }}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # File existence validation\n",
    "        if not os.path.exists(model_path):\n",
    "            return {{'error': f'Model file not found: {{model_path}}'}}\n",
    "        if not os.path.exists(scaler_path):\n",
    "            return {{'error': f'Scaler file not found: {{scaler_path}}'}}\n",
    "        \n",
    "        # Load model and scaler\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "        scaler = joblib.load(scaler_path)\n",
    "        \n",
    "        # Validate input (exactly 25 features expected)\n",
    "        if len(url_features) != 25:\n",
    "            return {{\n",
    "                'error': f'Expected exactly 25 features, got {{len(url_features)}}',\n",
    "                'expected_features': 25,\n",
    "                'received_features': len(url_features)\n",
    "            }}\n",
    "        \n",
    "        # Prepare and validate features\n",
    "        features = np.array(url_features, dtype=np.float32).reshape(1, -1)\n",
    "        if np.any(np.isnan(features)) or np.any(np.isinf(features)):\n",
    "            return {{'error': 'Input contains invalid values (NaN or Inf)'}}\n",
    "        \n",
    "        # Scale and reshape for LSTM\n",
    "        features_scaled = scaler.transform(features)\n",
    "        features_lstm = features_scaled.reshape(1, 1, -1)\n",
    "        \n",
    "        # Predict\n",
    "        probability = float(model.predict(features_lstm, verbose=0)[0][0])\n",
    "        probability = max(0, min(1, probability))  # Ensure valid range\n",
    "        \n",
    "        # Classify and assess confidence\n",
    "        prediction = 'phishing' if probability > 0.5 else 'legitimate'\n",
    "        confidence_score = probability if probability > 0.5 else (1 - probability)\n",
    "        \n",
    "        if confidence_score < 0.6:\n",
    "            confidence = 'low'\n",
    "        elif confidence_score < 0.8:\n",
    "            confidence = 'medium'\n",
    "        else:\n",
    "            confidence = 'high'\n",
    "        \n",
    "        return {{\n",
    "            'probability': probability,\n",
    "            'prediction': prediction,\n",
    "            'confidence': confidence,\n",
    "            'model_version': 'Enhanced_LSTM_v2.0',\n",
    "            'feature_count': 25\n",
    "        }}\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {{'error': f'Prediction failed: {{str(e)}}'}}\n",
    "\n",
    "# Feature order for reference:\n",
    "FEATURE_ORDER = {feature_mapping['basic_features'] + feature_mapping['count_features']}\n",
    "\n",
    "# Example usage:\n",
    "# features = [1, 5, 1, 0, 2, 1, 0, 3, 8, 1, 5, 2500, 0, 0.0, 0.0, 1.0, 2.0, 5.0, 1.0, 0.0, 3.0, 8.0, 1.0, 5.0, 2500.0]\n",
    "# result = predict_phishing(features)\n",
    "# print(f\"Prediction: {{result['prediction']}} ({{result['confidence']}} confidence)\")\n",
    "'''\n",
    "\n",
    "# Write deployment function to file\n",
    "with open('phishing_predictor_v2.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(deployment_code)\n",
    "\n",
    "print(f\"\\n‚úÖ Enhanced deployment function saved as 'phishing_predictor_v2.py'\")\n",
    "\n",
    "# Create feature configuration file\n",
    "feature_config = {\n",
    "    'version': '2.0',\n",
    "    'total_features': 25,\n",
    "    'feature_order': feature_mapping['basic_features'] + feature_mapping['count_features'],\n",
    "    'feature_groups': feature_mapping,\n",
    "    'model_requirements': {\n",
    "        'tensorflow_version': '>=2.8.0',\n",
    "        'input_shape': [1, 25],\n",
    "        'output_shape': [1],\n",
    "        'activation': 'sigmoid'\n",
    "    },\n",
    "    'deployment_notes': [\n",
    "        'Features must be provided in exact order specified',\n",
    "        'All 25 features are required for prediction',\n",
    "        'Feature scaling is applied automatically',\n",
    "        'Model expects LSTM input format: (samples, timesteps, features)'\n",
    "    ]\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('feature_config_v2.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(feature_config, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Feature configuration saved as 'feature_config_v2.json'\")\n",
    "\n",
    "# Create integration guide\n",
    "integration_guide = \"\"\"\n",
    "# Chrome Extension Integration Guide\n",
    "\n",
    "## Model Files Required:\n",
    "- phishing_lstm_model_final.h5 (trained model)\n",
    "- feature_scaler_final.pkl (feature scaler)\n",
    "- phishing_predictor_v2.py (prediction function)\n",
    "\n",
    "## Feature Collection:\n",
    "Your Chrome extension should collect these 25 features in exact order:\n",
    "\n",
    "### Basic Features (13):\n",
    "1. success (0/1)\n",
    "2. num_events (integer)\n",
    "3. ssl_valid (0/1)\n",
    "4. ssl_invalid (0/1)\n",
    "5. redirects (integer)\n",
    "6. forms (integer)\n",
    "7. password_fields (integer)\n",
    "8. iframes (integer)\n",
    "9. scripts (integer)\n",
    "10. suspicious_keywords (integer)\n",
    "11. external_requests (integer)\n",
    "12. page_load_time (milliseconds)\n",
    "13. has_errors (0/1)\n",
    "\n",
    "### Count Features (12):\n",
    "14. count_ssl_invalid (float)\n",
    "15. count_webdriver_error (float)\n",
    "16. count_ssl_valid (float)\n",
    "17. count_redirects (float)\n",
    "18. count_external_requests (float)\n",
    "19. count_forms_detected (float)\n",
    "20. count_password_fields (float)\n",
    "21. count_iframes_detected (float)\n",
    "22. count_scripts_detected (float)\n",
    "23. count_suspicious_keywords (float)\n",
    "24. count_page_load_time (float)\n",
    "\n",
    "## Usage Example:\n",
    "```python\n",
    "from phishing_predictor_v2 import predict_phishing\n",
    "\n",
    "# Collect features from URL\n",
    "features = collect_url_features(url)  # Your implementation\n",
    "result = predict_phishing(features)\n",
    "\n",
    "if 'error' in result:\n",
    "    print(f\"Error: {result['error']}\")\n",
    "else:\n",
    "    print(f\"Prediction: {result['prediction']}\")\n",
    "    print(f\"Confidence: {result['confidence']}\")\n",
    "    print(f\"Probability: {result['probability']:.3f}\")\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "with open('chrome_extension_integration.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(integration_guide)\n",
    "\n",
    "print(f\"‚úÖ Integration guide saved as 'chrome_extension_integration.md'\")\n",
    "\n",
    "print(f\"\\nüéØ Deployment Function Status:\")\n",
    "print(f\"   ‚úÖ Enhanced error handling implemented\")\n",
    "print(f\"   ‚úÖ Feature count validation (25 features)\")\n",
    "print(f\"   ‚úÖ Input validation and sanitization\") \n",
    "print(f\"   ‚úÖ Model compatibility verification\")\n",
    "print(f\"   ‚úÖ Comprehensive documentation created\")\n",
    "\n",
    "print(f\"\\nüìÅ Files ready for Chrome extension:\")\n",
    "print(f\"   - phishing_predictor_v2.py (enhanced prediction function)\")\n",
    "print(f\"   - feature_config_v2.json (feature specifications)\")\n",
    "print(f\"   - chrome_extension_integration.md (integration guide)\")\n",
    "\n",
    "print(f\"\\nüöÄ Deployment function ready for production use!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
